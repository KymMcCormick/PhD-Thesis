---
title: "Testing eyewitness data against the Block-Marschak inequalities"
author: "Kym McCormick"
date: "3 May 2019"
output:
  word_document: default
  pdf_document: default
  html_notebook: default
---
```{r setup, include=FALSE, results='hide'}

knitr::opts_chunk$set(echo = TRUE)

#For fitting the Block-Marschack and the other inequalities, we need a function that solves quadratic equations with inequality constraints. R offers several such packages, see section 'Quadratic Optimization' on: https://cran.r-project.org/view=Optimization Initially, we used the most popular package, quadprog (https://cran.r-project.org/package=quadprog) for this purpose. However, in some cases the function got stuck. Consequently, we tried other packages. Frr example, we observed good, albeit slow, results with Dykstra (https://cran.r-project.org/package=Dykstra). So all results reported here should replicate with Dykstra as well. We finally settled on quadprogpp which is a new and fast implementation of quadprog, which currently is only available from github: https://github.com/fnoorian/quadprogpp  It requires a C++ compiler (e.g., Rtools on Windows or Xtools on Mac) and can then be installed via devtools.

library("psych", lib.loc="~/R/win-library/3.5")
library("tidyverse", lib.loc="~/R/win-library/3.5")
library("jsonlite", lib.loc="~/R/win-library/3.5")

#if (!(require("devtools"))) install.packages("devtools")
#devtools::install_github("fnoorian/quadprogpp", force = TRUE)
library("quadprogpp", lib.loc="~/R/win-library/3.5") ## for fitting Block-Marschak
library("MPTinR", lib.loc="~/R/win-library/3.5")

```

```{r data wrangling}
setwd("C:/Users/mccormick/GitHub/PhD-Thesis")

data <- read.csv("data/Experiment 3/experiment3data.csv")


din <- data %>%
  select(uid,
         condition, 
         Test_T1_suspectIdentified, 
         confidence_rating, 
         justification_justification, 
         Rank_T1_selectionOrder, 
         demographics_age, 
         demographics_gender, 
         demographics_country)%>%
  filter(demographics_country == "USA", !is.na(confidence_rating)) %>%
  separate(condition,c("memory","expectation","target"))  %>%
  separate(Rank_T1_selectionOrder,c("Rank_1","Rank_2","Rank_3","Rank_4","Rank_5","Rank_6","Rank_7","Rank_8"))

din = mutate(din, decile = ntile(din$confidence_rating,10))

din$CID <- if_else(din$target == "P" & din$Test_T1_suspectIdentified == "F68", 1, 0)
din$Miss <- if_else(din$target == "P" & din$Test_T1_suspectIdentified == "Silhouette", 1, 0)
din$CR <- if_else(din$target == "A" & din$Test_T1_suspectIdentified == "Silhouette", 1, 0)
din$TPFoilID <- if_else(din$target == "P" & din$Test_T1_suspectIdentified != "F68", 1, 0)
din$TAFoilID <- if_else(din$target == "A" & din$Test_T1_suspectIdentified != "Silhouette", 1, 0)
din$n <- if_else(!is.na(din$demographics_country) == "USA",1,0)
din$R1_Corr <- if_else(din$target == "P" & din$Rank_1 == "F68", 1, 0)
din$R2_Corr <- if_else(din$target == "P" & din$Rank_2 == "F68", 1, 0)
din$R3_Corr <- if_else(din$target == "P" & din$Rank_3 == "F68", 1, 0)
din$R4_Corr <- if_else(din$target == "P" & din$Rank_4 == "F68", 1, 0)
din$R5_Corr <- if_else(din$target == "P" & din$Rank_5 == "F68", 1, 0)
din$R6_Corr <- if_else(din$target == "P" & din$Rank_6 == "F68", 1, 0)
din$R7_Corr <- if_else(din$target == "P" & din$Rank_7 == "F68", 1, 0)
din$R8_Corr <- if_else(din$target == "P" & din$Rank_8 == "F68", 1, 0)

write.csv(din, file = "Experiment3dataCleaned.csv")
```

##Demographics                         ##
```{r demographics}
#length(unique(din$uid))

describe(din$demographics_age)

demo <- din %>% 
  select(demographics_age, demographics_gender, demographics_country)# %>% 

demo %>% 
  select(-demographics_age) %>%
  map(~prop.table(table(.)))
```
##Identification Data

 
Number of Correct and False IDs per confidence decile

```{r}

ID_dat <- din %>% 
  group_by(decile) %>%
  summarise(Correct_ID = sum(CID),
            False_ID = sum(TAFoilID)/8,
            n = n())  

ID_dat

```
Vector of Correct ID and False ID counts for each confidence decile. Note that False ID counts are the number of identifications from target absent lineups divided by the number of items within the lineup (n = 8)

```{r}
ID_dvector <- din %>% 
  group_by(decile) %>%
  summarise(Correct = sum(CID),
            False = sum(TAFoilID)/8,
            n = n())  %>%
  select(-decile,-n) %>% 
  as.matrix() %>% 
  t() %>% 
  as.vector

ID_dvector


```
Vector of CIDs and FIDs for each confidence decile. Note that FIDs are calculated using Wixted & Mickes method, as per above.

```{r}
ID_prop_vector <- din %>% 
  group_by(decile) %>% 
  summarise(CID = sum(CID)/sum(n),
            FID = sum(TAFoilID)/8/sum(n)) %>% 
  select(-decile) %>% 
  as.matrix() %>% 
  t() %>% 
  as.vector

ID_prop_vector



```

##Ranking Data

Proportional correct 
```{r}
Rank_prop <- din  %>%
  filter(target == "P")%>%
  group_by(memory) %>%
  summarise(Rank_1 = sum(R1_Corr)/sum(n),
            Rank_2 = sum(R2_Corr)/sum(n),
            Rank_3 = sum(R3_Corr)/sum(n),
            Rank_4 = sum(R4_Corr)/sum(n),
            Rank_5 = sum(R5_Corr)/sum(n),
            Rank_6 = sum(R6_Corr)/sum(n),
            Rank_7 = sum(R7_Corr)/sum(n),
            Rank_8 = sum(R8_Corr)/sum(n),
            n = n()
            )
  Rank_prop

  matplot(t(Rank_prop[,2:9]), type = "b", bty="l", pch=c(19,17), ylab = "Proportion Correct", xlab = "Rank position")
  legend("topright", legend = c("Strong memory","Weak memory"),pch =c(19,17), col = c("black","red"), inset = .05)
  box("plot")
```

```{r}
Cond_Cum_Rank <- din %>% 
  filter(target == "P") %>%
  group_by(memory)%>%
  summarise(r1 = sum(R1_Corr),
            r2 = sum(R2_Corr),
            r3 = sum(R3_Corr),
            r4 = sum(R4_Corr),
            r5 = sum(R5_Corr),
            r6 = sum(R6_Corr),
            r7 = sum(R7_Corr),
            r8 = sum(R8_Corr)
            ) %>% 
    select(-memory)%>%
  as.matrix() %>% 
  #t() %>% 
  as.vector%>%
  structure(.Dim= c(2L,8L))

Cond_Cum_Rank <- Cond_Cum_Rank %>%
  mutate (c1 = r1/377,
             c2 = r2/(377-r1))
Cond_Cum_Rank

```

```{r}
Rank_dvector <- din %>% 
  filter(target == "P") %>%
  group_by(memory)%>%
  summarise(Rank_1_CID = sum(R1_Corr),
            Rank_2_CID = sum(R2_Corr),
            Rank_3_CID = sum(R3_Corr),
            Rank_4_CID = sum(R4_Corr),
            Rank_5_CID = sum(R5_Corr),
            Rank_6_CID = sum(R6_Corr),
            Rank_7_CID = sum(R7_Corr),
            Rank_8_CID = sum(R8_Corr)
            ) %>% 
    select(-memory)%>%
  as.matrix() %>% 
  #t() %>% 
  as.vector%>%
  structure(.Dim= c(2L,8L))

Rank_dvector

```


```{r}


expSDTrank <- function(Q, param.names, n.params, tmp.env){
  
  n <- 8
  
  e <- vector("numeric", n)
  
    mu <- Q[1]
    ss <- Q[2]
    
    G <- function(x,i) {
        (pnorm(x)^(n-i))*dnorm(x, mean = mu, sd = ss)*(1-pnorm(x))^(i-1)*choose(n-1, i-1)
    }
    
    for (ii in 1:n) {
        e[ii] <- integrate(G,-Inf,Inf,i = ii, rel.tol = .Machine$double.eps^0.5)$value
    }
    return(e)
}

SDTrank <- function(Q, data, param.names, n.params, tmp.env, lower.bound, upper.bound){
    e <- expSDTrank(Q, param.names, n.params, tmp.env)
    LL <- -sum(data[data!=0]*log(e[data!=0]))
    return(LL)
}

Rank_strong <- fit.mptinr(
  data = Rank_dvector[1,], 
  objective = SDTrank, 
  param.names = c("mu", "sigma"), 
  categories.per.type = 8, 
  prediction = expSDTrank, 
  lower.bound = c(0,0.1), 
  upper.bound = Inf,
  starting.values = c(1,1)
)

Rank_weak <- fit.mptinr(
  data = Rank_dvector[2,], 
  objective = SDTrank, 
  param.names = c("mu", "sigma"), 
  categories.per.type = 8, 
  prediction = expSDTrank, 
  lower.bound = c(0,0.1), 
  upper.bound = Inf,
  starting.values = c(1,1)
)
```

```{r}
Rank_strong$goodness.of.fit
Rank_strong$parameters
```

```{r}
Rank_weak$goodness.of.fit
Rank_weak$parameters
```


